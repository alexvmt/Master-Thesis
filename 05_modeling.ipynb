{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### MODELS #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting modeling...\n"
     ]
    }
   ],
   "source": [
    "print('Starting modeling...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time:  2019-02-17 18:12:26.787804\n"
     ]
    }
   ],
   "source": [
    "### import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime,date\n",
    "\n",
    "start_time = datetime.now()\n",
    "print('Start time: ', start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### SELECT INPUT FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input file selected:  3_day_sample_preprocessed_with_additional_features.tsv.gz\n"
     ]
    }
   ],
   "source": [
    "#input_file = '3_day_sample_preprocessed.tsv.gz'\n",
    "input_file = '3_day_sample_preprocessed_with_additional_features.tsv.gz'\n",
    "#input_data = '6_week_sample_preprocessed.tsv.gz'\n",
    "#input_file = '6_week_sample_preprocessed_with_additional_features.tsv.gz'\n",
    "#input_data = '12_week_sample_preprocessed.tsv.gz'\n",
    "#input_file = '12_week_sample_preprocessed_with_additional_features.tsv.gz'\n",
    "#input_data = '25_week_sample_preprocessed.tsv.gz'\n",
    "#input_file = '25_week_sample_preprocessed_with_additional_features.tsv.gz'\n",
    "\n",
    "print('Input file selected: ', input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "##### LOAD DATA\n",
    "print('Loading data...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data complete.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/processed_data/'+input_file, compression='gzip', sep='\\t', low_memory=False, encoding='iso-8859-1', parse_dates=['hit_time_gmt'])\n",
    "\n",
    "print('Loading data complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating descriptives...\n"
     ]
    }
   ],
   "source": [
    "##### DESCRIPTIVES\n",
    "print('Calculating descriptives...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample descriptives:  {'unique_visitors': 188746, 'visits': 214009, 'percentage_purchases': 0.0077, 'features': 118}\n",
      "Calculating descriptives complete.\n"
     ]
    }
   ],
   "source": [
    "descriptives_dict = {'unique_visitors' : df['visitor_id'].nunique(),\n",
    "                     'visits' : df.shape[0],\n",
    "                     'percentage_purchases' : round(df['purchase'].value_counts()[1]/(len(df['purchase'])), 4),\n",
    "                     'features' : df.shape[1]}\n",
    "print('Sample descriptives: ', descriptives_dict)\n",
    "\n",
    "print('Calculating descriptives complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### PREPARE DATA FOR MODELING #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data for modeling...\n"
     ]
    }
   ],
   "source": [
    "print('Preparing data for modeling...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns that have many missing values, are static or where their usefulness is unclear\n",
    "cols_to_drop = ['visitor_id_lag', \n",
    "                'last_hit_time_gmt_visit', \n",
    "                'last_hit_time_gmt_visit_lag',\n",
    "                'days_since_last_visit',\n",
    "                'purchase_date',\n",
    "                'purchase_date_lag',\n",
    "                'days_since_last_purchase',\n",
    "                'country', \n",
    "                'geo_region',\n",
    "                'geo_city',\n",
    "                'geo_zip',\n",
    "                'geo_dma',\n",
    "                'post_channel',\n",
    "                'search_page_num',\n",
    "                'net_promoter_score_raw_(v10)_-_user',\n",
    "                'registration_(any_form)_(e20)',\n",
    "                'hit_of_logged_in_user_(e23)', # duplicate of login_status\n",
    "                'newsletter_signup_(any_form)_(e26)', \n",
    "                'newsletter_subscriber_(e27)', \n",
    "                'user_gender_(v61)',\n",
    "                'user_age_(v62)',\n",
    "                'login_success_(e72)', \n",
    "                'logout_success_(e73)', \n",
    "                'login_fail_(e74)', \n",
    "                'registration_fail_(e75)',\n",
    "                'product_categories_level_1',\n",
    "                'product_categories_level_2',\n",
    "                'product_categories_level_3']\n",
    "\n",
    "for col in cols_to_drop:\n",
    "    if col in df.columns:\n",
    "        df.drop(col, axis=1, inplace=True)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2 days for training\n",
    "y_train = df[df['hit_time_gmt'] <= '2016-05-10 23:59:59']['purchase']\n",
    "X_train = df[df['hit_time_gmt'] <= '2016-05-10 23:59:59'].copy()\n",
    "X_train = X_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptives training set:  {'unique_visitors': 136223, 'visits': 152283, 'percentage_purchases': 0.0072, 'features': 90, 'days_for_training': 2}\n"
     ]
    }
   ],
   "source": [
    "train_descriptives_dict = {'unique_visitors' : X_train['visitor_id'].nunique(),\n",
    "                           'visits' : X_train.shape[0],\n",
    "                           'percentage_purchases' : round(y_train.value_counts()[1]/(len(y_train)), 4),\n",
    "                           'features' : df.shape[1], \n",
    "                           'days_for_training': (X_train['hit_time_gmt'].max() - X_train['hit_time_gmt'].min()).days}\n",
    "X_train.drop(['purchase', 'hit_time_gmt', 'visitor_id'], axis=1, inplace=True)\n",
    "print('Descriptives training set: ', train_descriptives_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1 day for testing\n",
    "y_test = df[df['hit_time_gmt'] > '2016-05-10 23:59:59']['purchase']\n",
    "X_test = df[df['hit_time_gmt'] > '2016-05-10 23:59:59'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptives test set:  {'unique_visitors': 57689, 'visits': 61726, 'percentage_purchases': 0.0088, 'features': 90, 'days_for_training': 0}\n"
     ]
    }
   ],
   "source": [
    "test_descriptives_dict = {'unique_visitors' : X_test['visitor_id'].nunique(),\n",
    "                          'visits' : X_test.shape[0],\n",
    "                          'percentage_purchases' : round(y_test.value_counts()[1]/(len(y_test)), 4),\n",
    "                          'features' : X_test.shape[1], \n",
    "                          'days_for_training': (X_test['hit_time_gmt'].max() - X_test['hit_time_gmt'].min()).days}\n",
    "X_test.drop(['purchase', 'hit_time_gmt', 'visitor_id'], axis=1, inplace=True)\n",
    "print('Descriptives test set: ', test_descriptives_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data for modeling complete.\n"
     ]
    }
   ],
   "source": [
    "print('Preparing data for modeling complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training models...\n"
     ]
    }
   ],
   "source": [
    "##### TRAIN AND TEST MODELS #####\n",
    "print('Training models...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alex.merdian-tarko\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "### import libraries for modeling and performance evaluation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold,cross_val_score\n",
    "from sklearn.metrics import accuracy_score,roc_curve,auc,confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.994110 (mean accuracy) 0.004380 (standard deviation) 0:02:36.173186 (cv duration)\n"
     ]
    }
   ],
   "source": [
    "### build models, do 10-fold cross validation and evaluate each model in turn\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "#models.append(('KNN', KNeighborsClassifier()))\n",
    "#models.append(('CART', DecisionTreeClassifier()))\n",
    "#models.append(('NB', GaussianNB()))\n",
    "#models.append(('SVM', SVC()))\n",
    "#models.append(('RF', RandomForestClassifier()))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in models:\n",
    "    \n",
    "    cv_start_time = datetime.now()\n",
    "    kfold = KFold(n_splits=10, random_state=0)\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "    cv_duration = datetime.now() - cv_start_time\n",
    "    \n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    \n",
    "    cv_msg = '%s: %f (mean accuracy) %f (standard deviation) %s (cv duration)' % (name, cv_results.mean(), cv_results.std(), cv_duration)\n",
    "    print(cv_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR :  0:00:18.046473 (training_duration)\n",
      "Training models complete.\n"
     ]
    }
   ],
   "source": [
    "### train each model in turn\n",
    "for name, model in models:\n",
    "    \n",
    "    training_start_time = datetime.now()\n",
    "    model.fit(X_train, y_train, random_state=0)\n",
    "    training_duration = (datetime.now() - training_start_time)\n",
    "    \n",
    "    print(name, ': ', training_duration, '(training_duration)')\n",
    "    \n",
    "print('Training models complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluating models...\n"
     ]
    }
   ],
   "source": [
    "##### EVALUATE MODELS #####\n",
    "print('Starting evaluating models...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR :  0:00:00.067232 (test_duration)\n",
      "Accuracy: 99.35%\n",
      "\n",
      "\n",
      "AUC: 0.68\n",
      "\n",
      "\n",
      "Confusion matrix\n",
      "[[61127    53]\n",
      " [  347   199]]\n",
      "true negatives C[0,0] false negatives C[1,0] true positives C[1,1] false positives is C[0,1]\n",
      "\n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00     61180\n",
      "          1       0.79      0.36      0.50       546\n",
      "\n",
      "avg / total       0.99      0.99      0.99     61726\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### test and evaluate each model in turn\n",
    "for name, model in models:\n",
    "    \n",
    "    test_start_time = datetime.now()\n",
    "    y_pred = model.predict(X_test)\n",
    "    test_duration = datetime.now() - test_start_time\n",
    "    \n",
    "    print(name, ': ', test_duration, '(test_duration)')\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print('Accuracy: %.2f%%' % (accuracy * 100.0))\n",
    "    print('\\n')\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "    print('AUC: %.2f' % auc(fpr, tpr))\n",
    "    print('\\n')\n",
    "    \n",
    "    print('Confusion matrix')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print('true negatives C[0,0] false negatives C[1,0] true positives C[1,1] false positives is C[0,1]')\n",
    "    print('\\n')\n",
    "    \n",
    "    print('Classification report')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modeling and evaluation complete.\n",
      "Run time:  0:03:19.468912\n"
     ]
    }
   ],
   "source": [
    "print('Modeling and evaluation complete.')\n",
    "print('Run time: ', datetime.now() - start_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
