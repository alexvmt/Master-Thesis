{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### MODELING #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Starting modeling...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime,date\n",
    "\n",
    "start_time = datetime.now()\n",
    "print('Start time: ', start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### SELECT INPUT FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_file = '3_day_sample_preprocessed.tsv.gz'\n",
    "input_file = '3_day_sample_preprocessed_with_additional_features.tsv.gz'\n",
    "#input_file = '6_week_sample_preprocessed.tsv.gz'\n",
    "#input_file = '6_week_sample_preprocessed_with_additional_features.tsv.gz'\n",
    "#input_file = '12_week_sample_preprocessed.tsv.gz'\n",
    "#input_file = '12_week_sample_preprocessed_with_additional_features.tsv.gz'\n",
    "#input_file = '25_week_sample_preprocessed.tsv.gz'\n",
    "#input_file = '25_week_sample_preprocessed_with_additional_features.tsv.gz'\n",
    "\n",
    "print('Input file selected: ', input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### LOAD DATA\n",
    "print('Loading data...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/processed_data/'+input_file, compression='gzip', sep='\\t', low_memory=False, encoding='iso-8859-1', parse_dates=['hit_time_gmt', 'date_time'])\n",
    "\n",
    "print('Loading data complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### DESCRIPTIVES\n",
    "print('Calculating descriptives...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptives_dict = {'unique visitors' : df['visitor_id'].nunique(),\n",
    "                     'visits' : df.shape[0],\n",
    "                     'conversion rate' : round(df['purchase'].value_counts()[1]/(len(df['purchase'])), 4),\n",
    "                     'features' : df.shape[1]}\n",
    "print('Sample descriptives: ', descriptives_dict)\n",
    "\n",
    "print('Calculating descriptives complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### PREPARE DATA FOR MODELING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Preparing data for modeling...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns that have many missing values, are static or where their usefulness is unclear\n",
    "cols_to_drop = ['visitor_id_lag', \n",
    "                'last_hit_time_gmt_visit', \n",
    "                'last_hit_time_gmt_visit_lag',\n",
    "                'last_date_time_visit',\n",
    "                'days_since_last_visit',\n",
    "                'purchase_date',\n",
    "                'purchase_date_lag',\n",
    "                'days_since_last_purchase',\n",
    "                'country', \n",
    "                'geo_region',\n",
    "                'geo_city',\n",
    "                'geo_zip',\n",
    "                'geo_dma',\n",
    "                'post_channel',\n",
    "                'search_page_num',\n",
    "                'net_promoter_score_raw_(v10)_-_user',\n",
    "                'registration_(any_form)_(e20)',\n",
    "                'hit_of_logged_in_user_(e23)', # duplicate of login_status\n",
    "                'newsletter_signup_(any_form)_(e26)', \n",
    "                'newsletter_subscriber_(e27)', \n",
    "                'user_gender_(v61)',\n",
    "                'user_age_(v62)',\n",
    "                'login_success_(e72)', \n",
    "                'logout_success_(e73)', \n",
    "                'login_fail_(e74)', \n",
    "                'registration_fail_(e75)',\n",
    "                'product_categories_level_1',\n",
    "                'product_categories_level_2',\n",
    "                'product_categories_level_3']\n",
    "\n",
    "for col in cols_to_drop:\n",
    "    if col in df.columns:\n",
    "        df.drop(col, axis=1, inplace=True)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### generate training set from 2/3 of the data\n",
    "y_train = df[df['date_time'] <= '2016-05-10 23:59:59']['purchase']\n",
    "X_train = df[df['date_time'] <= '2016-05-10 23:59:59'].copy()\n",
    "X_train = X_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_descriptives_dict = {'unique visitors' : X_train['visitor_id'].nunique(),\n",
    "                           'visits' : X_train.shape[0],\n",
    "                           'conversion rate' : round(y_train.value_counts()[1]/(len(y_train)), 4),\n",
    "                           'features' : df.shape[1] - 4, \n",
    "                           'days for training': (X_train['hit_time_gmt'].max() - X_train['hit_time_gmt'].min()).days}\n",
    "X_train.drop(['purchase', 'hit_time_gmt', 'date_time','visitor_id'], axis=1, inplace=True)\n",
    "print('Descriptives training set: ', train_descriptives_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### generate test set from 1/3 of the data\n",
    "y_test = df[df['date_time'] > '2016-05-10 23:59:59']['purchase']\n",
    "X_test = df[df['date_time'] > '2016-05-10 23:59:59'].copy()\n",
    "X_test = X_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_descriptives_dict = {'unique visitors' : X_test['visitor_id'].nunique(),\n",
    "                          'visits' : X_test.shape[0],\n",
    "                          'conversions rate' : round(y_test.value_counts()[1]/(len(y_test)), 4),\n",
    "                          'features' : X_test.shape[1] - 4, \n",
    "                          'days for testing': (X_test['hit_time_gmt'].max() - X_test['hit_time_gmt'].min()).days}\n",
    "X_test.drop(['purchase', 'hit_time_gmt', 'date_time', 'visitor_id'], axis=1, inplace=True)\n",
    "print('Descriptives test set: ', test_descriptives_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Preparing data for modeling complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### TRAIN, TEST AND EVALUATE MODELS\n",
    "print('Starting training, testing and evaluating models...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import libraries for modeling and performance evaluation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "#from sklearn.naive_bayes import GaussianNB\n",
    "#from sklearn.svm import SVC\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold,cross_val_score\n",
    "from sklearn.metrics import accuracy_score,roc_curve,auc,confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### build models, do 10-fold cross validation and evaluate each model in turn\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "#models.append(('KNN', KNeighborsClassifier()))\n",
    "#models.append(('CART', DecisionTreeClassifier()))\n",
    "#models.append(('NB', GaussianNB()))\n",
    "#models.append(('SVM', SVC()))\n",
    "#models.append(('RF', RandomForestClassifier()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test and evaluate each model in turn\n",
    "for name, model in models:\n",
    "    \n",
    "    print('Training ', name, '...')\n",
    "    training_start_time = datetime.now()\n",
    "    model.fit(X_train, y_train)\n",
    "    training_duration = (datetime.now() - training_start_time)\n",
    "    print('Training ', name, 'complete, training_duration: ', training_duration)\n",
    "    \n",
    "    print('Testing ', name, '...')\n",
    "    test_start_time = datetime.now()\n",
    "    y_pred = model.predict(X_test)\n",
    "    test_duration = datetime.now() - test_start_time\n",
    "    print('Testing ', name, 'complete, test_duration: ', test_duration)\n",
    "    \n",
    "    print('Evaluating ', name, '...')\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print('Accuracy: %.2f%%' % (accuracy * 100.0))\n",
    "    print('\\n')\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "    print('AUC: %.2f' % auc(fpr, tpr))\n",
    "    print('\\n')\n",
    "    print('Confusion matrix')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print('true negatives C[0,0] false negatives C[1,0] true positives C[1,1] false positives is C[0,1]')\n",
    "    print('\\n')\n",
    "    print('Classification report')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print('Evaluating ', name, 'complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### SMOTE FOR NOMINAL AND CONTINUOUS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Starting resampling...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTENC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTENC(random_state=42, categorical_features=[17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
    "                                                    35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52,\n",
    "                                                    53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70,\n",
    "                                                    71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 85, 86])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resampling\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('old training set size', X_train.shape[0])\n",
    "print('new training set size', X_train_res.shape[0])\n",
    "print('old conversion rate', round(y_train.value_counts()[1]/(len(y_train)), 4))\n",
    "print('new conversion rate', round(y_train_res.sum()/(len(y_train_res)), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Resampling complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Reevaluation models...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test and evaluate each model in turn using resampled data\n",
    "for name, model in models:\n",
    "    \n",
    "    print('Training ', name, '...')\n",
    "    training_start_time = datetime.now()\n",
    "    model.fit(X_train_res, y_train_res)\n",
    "    training_duration = (datetime.now() - training_start_time)\n",
    "    print('Training ', name, 'complete, training_duration: ', training_duration)\n",
    "    \n",
    "    print('Testing ', name, '...')\n",
    "    test_start_time = datetime.now()\n",
    "    y_pred = model.predict(X_test)\n",
    "    test_duration = datetime.now() - test_start_time\n",
    "    print('Testing ', name, 'complete, test_duration: ', test_duration)\n",
    "    \n",
    "    print('Evaluating ', name, '...')\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print('Accuracy: %.2f%%' % (accuracy * 100.0))\n",
    "    print('\\n')\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "    print('AUC: %.2f' % auc(fpr, tpr))\n",
    "    print('\\n')\n",
    "    print('Confusion matrix')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print('true negatives C[0,0] false negatives C[1,0] true positives C[1,1] false positives is C[0,1]')\n",
    "    print('\\n')\n",
    "    print('Classification report')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print('Evaluating ', name, 'complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Reevaluating models complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Modeling complete.')\n",
    "print('Run time: ', datetime.now() - start_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
